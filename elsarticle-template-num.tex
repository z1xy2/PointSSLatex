 %% 
%% Copyright 2007-2025 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%% $Id: elsarticle-template-num.tex 272 2025-01-09 17:36:26Z rishi $
%%
\sloppy
\documentclass[preprint,12pt]{elsarticle}
\usepackage[UTF8]{ctex}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{booktabs}
\usepackage{comment}
%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsmath package provides various useful equation environments.
\usepackage{amsmath}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}
\usepackage{subfigure}
%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\journal{Neural Networks}
\usepackage{cleveref}
\crefname{figure}{Fig.}{Figs.} % 小写引用格式
\crefname{equation}{Eq.}{Eqs.} % 大写引用格式
\crefname{table}{Table}{Table}  
\renewcommand{\figurename}{Fig.}
\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

\title{PointSS：一种基于几何感知的多尺度状态空间点云分析方法}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

\author{Xinyuan Zhang, Xin Wang} %% Author name

%% Author affiliation
\affiliation{organization={Jilin University},%Department and Organization
            addressline={}, 
            city={},
            postcode={}, 
            state={},
            country={China}}

%% Abstract
\begin{abstract}
%% Text of abstract

点云作为三维空间的离散化表示，在自动驾驶、机器人导航、虚拟现实等领域具有广泛应用。准确提取点云的几何特征和语义信息对下游任务至关重要。然而，点云数据固有的无序性、稀疏性和不规则性给特征提取带来了巨大挑战。传统基于卷积的方法难以直接处理点云的非结构化特性，而基于Transformer的方法虽然能够捕获全局依赖，但其二次复杂度限制了在大规模点云场景中的应用。

近年来，源自自然语言处理领域的Mamba模型因其线性复杂度和强大的序列建模能力，在点云分析领域得到了广泛应用并取得了良好效果。然而，将Mamba应用于点云仍面临诸多挑战。其一，由于Mamba要求输入顺序序列，因此现有方案通常需要先将无序的点云序列化。但这种序列化会导致一些空间上相邻的点在序列中被分离，而关键几何结构信息通常由空间最邻近点提供，因此会造成几何信息的丢失。这种几何丢失使得Mamba的线性状态传递机制难以隐式学习到完整的几何结构特征。其二，在长序列多尺度特征学习中，模型通常无法区分邻近点和远处点的重要性权重，导致无法精确捕获局部细节信息和全局高层次信息。同时，序列化也为本质上无序的点云强加了不必要的因果关系。

为解决相关问题，本文提出了一种基于自适应尺度解耦状态空间模型的点云特征提取神经网络PointSS。针对几何学习困难问题，我们设计了全局几何感知机制(Global Geometry-Aware Mechanism, GGAM)，通过高效的窗口化邻域提取点云的几何先验(曲率和法向量)，并利用双序列化融合和全局交叉注意力机制为Mamba显式注入几何信息，以补偿其因序列化点云特征学习下存在的几何特征学习不足问题，提升模型对点云几何结构的建模能力。

针对长序列下特征粒度单一与因果关系强加的问题，我们提出了自适应尺度解耦状态空间模型(Adaptive Scale-Decoupled State Space Model, ASD-SSM)。ASD-SSM通过轻量级参数生成器为不同尺度动态生成定制化的SSM参数，使粗尺度倾向于捕获长程依赖，细尺度倾向于快速响应局部变化，在尊重点云无序性的同时实现了层次化的多尺度特征学习。该方法在仅增加约20\%参数量的情况下，性能接近完全独立参数方案（仅低0.6\% mIoU），显著提升了模型的参数效率和表达能力。

实验结果证明，所提出的算法较目前主流方法以及基于状态空间的点云分析方法有明显优势。在统一不使用预训练的情况下，在点云室内分割基准S3DIS中达到了75.2\%的mean Intersection over Union(mIoU)，以5.4\%的mIoU超过了性能最优的同类模型PCM。在3D分类基准ModelNet40中以1.9\%的整体正确率超过了性能最优的同类模型Mamba3D，达到96.0\%的准确率。
\end{abstract}

%%Graphical abstract
\begin{graphicalabstract}
%\includegraphics{grabs}
\end{graphicalabstract}


%% Keywords
\begin{keyword}
%% keywords here, in the form: keyword \sep keyword

%% PACS codes here, in the form: \PACS code \sep code
Point cloud analysis, State space models, Multi scale feature fusion, Point cloud serialization, Geometric structure.
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%% Add \usepackage{lineno} before \begin{document} and uncomment 
%% following line to enable line numbers
%% \linenumbers

%% main text
%%

%% Use \section commands to start a section
\section{Introduction}
\label{sec1}

点云分析被广泛应用于自动驾驶、增强现实（AR）/虚拟现实（VR）领域，相较于二维图像，点云有着稀疏性、无序性等特点。随着大规模高密度点云场景的获取成本逐渐降低，此类数据在自动驾驶、机器人导航等领域得到越来越广泛的应用。

点云分析最初依赖PointNet\cite{pointnet,PointNet++}等基于邻近点搜索和MLP的方法，虽避免了中间表示转换，但特征提取能力有限。随后，Transformer\cite{pt,ptv3,superpoint} 因其更强的全局建模能力被广泛应用，却受限于二次计算复杂度与长序列理解不足。这些缺陷已成为点云大模型与大规模场景分析的发展瓶颈。受自然语言处理领域时序化特征提取方案的启发 \cite{ssm,Mamba,Lstm}，越来越多Mamba\cite{Mamba,VisionMamba}相关工作被应用到点云分析，如PCM(Point Cloud Mamba)\cite{pcm}和PointMamba\cite{PointMamba}。其线性时间复杂度在处理大规模点云数据时具有明显的效率优势，并在特征提取任务中表现出稳定的识别精度。

目前基于Mamba的点云分析方法还有两个关键问题需要解决。其一：虽然序列化方法能在局部窗口内保持空间邻近性，但Mamba的线性状态传递机制无法有效关联空间邻近但序列距离较远的点（割裂点），导致模型难以综合所有空间邻居的几何信息，从而影响对复杂形状的精确学习。我们称这种情况为几何丢失。其二：当前的模型对于长序列下特征提取粒度单一，且为点云强加了因果关系，无法同时捕捉不同层次的特征信息。

几何丢失问题出现的核心原因在于Mamba的线性状态传递机制与点云空间特性的矛盾。虽然基于空间填充曲线的序列化方法（如Z-order和Hilbert编码）在局部窗口内能够较好地保持空间邻近性，但无法保证所有空间邻近的点在序列中也相邻。Mamba通过状态向量进行时序信息传递，在顺序特征提取过程中，状态向量会逐渐更新以吸收新点的信息。关键问题在于：割裂点的几何信息在状态传递过程中逐渐衰减，当模型处理某个点时，其空间邻近但序列距离较远的邻居点信息已经丢失，导致模型难以隐式学习到完整的几何结构特征。由于点云的几何结构信息（如曲面法向量、边缘曲率）通常由空间邻近点集合定义，割裂点的存在使得Mamba无法综合所有空间邻居的信息进行几何学习，从而影响对复杂形状（如墙与柱的边界、曲面过渡区域）的精确分割。例如，三维空间中距离仅0.1m的两个点，可能因x坐标差异被序列化为相隔数千点的位置，导致其k近邻集合在序列中被割裂，Mamba无法有效关联这些割裂点，最终导致分割效果不佳。如图\ref{fig:analysis}所示，我们以墙面与方柱的边界分割为例进行可视化：红色点为需要预测的中心点，绿色点代表空间邻近且序列邻近的点，其几何信息能通过Mamba状态传递正常学习。橙色点则为割裂点，空间邻近但序列距离远，其几何信息在到达中心点时已被遗忘。

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{picture/analysis.JPG}
	\caption{序列化后几何结构丢失可视化}
	\label{fig:analysis}
\end{figure}

长序列下特征粒度单一与因果关系强加的问题出现的核心原因在于，现有方法虽通过增加排序策略改善序列化效果，但在处理长序列点云时，受Mamba线性计算特性影响，无法在邻域内精准区分远近点的学习权重，难以同时捕捉邻近点的细节信息与较远点的高层次语义，导致特征提取的粒度与层次化不足。此外，这些方法常依赖对点云进行特定排序或结构化预处理，忽略了点云本质上的无序特性，为点云强加了因果关系，从而在一定程度上丢失了数据的多样性和原始特征分布的完整性，使模型对序列顺序过度敏感，输入顺序的变化可能导致完全不同的输出，降低模型的鲁棒性。

为解决上述问题，本文提出PointSS，一种基于自适应尺度解耦状态空间模型的点云分析方法。我们的主要贡献包括：

\begin{itemize}
	\item 提出了全局几何感知机制(GGAM)，通过高效的窗口化邻域提取几何先验（曲率、法向量），并利用双序列化融合、全局交叉注意力和自适应门控，为Mamba提供显式的几何感知能力，补偿序列化割裂导致的几何学习困难。

	\item 提出了自适应尺度解耦状态空间模型(ASD-SSM)。ASD-SSM通过尺度感知参数生成器为不同尺度动态生成定制化的SSM参数，使粗尺度捕获长程依赖，细尺度快速响应局部变化。该方法在尊重点云无序性的同时实现了层次化的多尺度特征学习，仅增加约20\%参数量即可达到接近完全独立参数方案的性能。

	\item 在S3DIS和ModelNet40等标准基准上进行了实验，PointSS超越了现有的基于Mamba的点云分析方法，在S3DIS上达到75.2\% mIoU，在ModelNet40上达到96.0\%准确率。消融实验验证了各组件的有效性。
\end{itemize}





\section{Related Work}
近年来，点云分析领域经历了从早期基于几何先验的方法到深度学习驱动的端到端模型的重要转变。研究人员针对点云数据的稀疏性、无序性和高维特性等挑战，提出了一系列创新性解决方案。本节将从深度学习在点云语义分析的发展、几何特征增强策略以及多尺度特征融合技术三个维度系统梳理相关工作，分析各方法的核心思想、技术贡献及其局限性。

\subsection{基于深度学习的点云语义分析}
早期的PointNet\cite{pointnet}作为开创性工作，通过对称函数（如最大池化）巧妙解决了点云无序性问题，设计了两级特征聚合
架构实现端到端处理。然而其全局池化策略虽能捕捉整体形状信息，但在局部几何细节建模方面存在明显不足。PointNet++\cite{PointNet++}提出分层特征学习框架，通过采样-分组-特征提取策略，在不同尺度上递归
应用PointNet结构，有效平衡了局部细节与全局结构的建模需求。随后，DGCNN\cite{DGCNN}引入动态图构建机制，在特征空间中定义邻域关系，显著增强了对复杂几何结构的适应能力。FusionNet\cite{FusionNet}通过
多分辨率特征提取模块实现多尺度特征融合，提升了分析精度。但基于CNN的方法仍受限于规则网格卷积和固定感受野，难以有效构建多尺度语义信息的层次信息矩阵。

随着Transformer在自然语言处理和计算机视觉领域的成功，点云分析迎来了新的发展机遇。Point Transformer\cite{pt}作为先驱工作，设计了专门的点云自注意力模块，通过位置编码和特征增强策略，实现了对点云几
何信息和语义特征的联合建模。其注意力计算不仅考虑特征相似性，还融入相对位置信息，使模型能够同时感知语义关联和空间邻近关系。PCT\cite{PCT}通过轻量化的注意力机制提升了特征提取效率，Point
Transformer V2\cite{ptv2}引入分组向量注意力机制有效降低了计算复杂度。PTv3\cite{ptv3}则采用简化设计理念，摒弃复杂的注意力交互机制，通过直接序列化策略取得了SOTA性能，证明了简洁设计的有效性      
。尽管Transformer方法在全局建模能力上表现卓越，但标准自注意力机制的$O(N^2)$复杂度使得模型在面对大规模点云时难以保持实时性，且其全局感知特性在精细几何建模任务中的局部结构细节敏感性不足。

为解决Transformer的计算复杂度瓶颈，基于状态空间模型（SSM）的方法成为新兴方向。Mamba\cite{Mamba}通过选择性状态空间机制实现高效序列建模，其线性时间复杂度为大规模点云处理提供了理论基础。PointMamba     
\cite{PointMamba}首次将Mamba架构引入点云分析，通过空间填充曲线将三维点云序列化为一维序列，能够以线性复杂度实现全局信息聚合。PCM\cite{pcm}进一步优化了序列化策略，提出空间相邻性保持的点云排序方法     
，并设计新的位置编码机制增强空间感知能力。然而，现有SSM方法在将三维非结构化数据适配到一维序列处理框架时面临本质性挑战：其一，PointMamba 依赖固定序列化规则处理点云，导致空间上邻近的点在序列中可能被割裂，使得法向量、曲率等由局部几何邻域定义的关键特征难以被有效建模，进而影响模型对复杂曲面、尖锐边缘等精细结构的表征能力;
其二，PCM 虽通过特定序列化策略缓解了割裂现象，但受限于 Mamba 线性计算框架，在长序列场景下无法为不同距离的邻域点动态分配差异化权重 —— 邻近点的细节几何信息（如高曲率区域的精确法向量变化）与较远点的全局语义关联（如部件间结构关系）未能在特征聚合中实现层次化区分，导致特征表达的粒度单一，难以兼顾局部几何细节与跨尺度语义关联。
\subsection{基于几何特征增强的点云分析方法}
点云数据本质上携带丰富的几何信息，如局部表面法向量、曲率、边缘特征等，这些几何特征对于理解三维结构至关重要。近年来，研究者们越来越关注如何显式地建模和利用这些几何特征来增强点云分析性能。

PointGA（Geometrically Aware Transformer）\cite{pointga}其核心思想是将原始三维坐标扩展为多维几何信息，为网络注入更多几何先验知识。该方法设计了适用于点云的三角位置编码机制     
，通过重构局部三角形结构来捕捉细粒度的几何关系。实验表明，显式的几何信息融入能够显著提升模型的特征表达能力。PointMSGT\cite{pointmsgt}提出了多尺度几何特征提取框架，其核心模块包括几何特征提取（GFE）和多尺度注意力（MSA）。GFE模块通过每个点的两个近邻重构三角形结构，利用三角形质心、法向量和平面常数提取详细的局部几何关系      
。这种几何建模策略在复杂场景下表现出较强的鲁棒性。在几何约束方面，最近的研究\cite{gsrnet,geotransformer}探索了利用几何一致性来改善点云配准和重建任务。这些方法通过引入几何约束（如距离保持、角度保持等）来规范特征学习过程，确保学习到的特征表示符合物理世界的几何规律。Geo-CNN\cite{geo-cnn}通过构建几何图（Geometric
Graph）来捕捉点云的几何特征，利用点之间的几何相似性定义边权重，但其需要额外的几何信息，依赖高质量的输入点云。

然而，现有的几何特征增强方法主要面临两个挑战：一是计算效率问题，精确的几何特征计算（如基于k近邻的法向量估计）往往计算代价较高，特别是在大规模点云上；二是特征融合问题，如何将几何特征与深度特征有     
效融合，避免信息冗余和特征冲突，仍然是一个开放性问题。大多数方法依赖传统的KNN搜索进行几何关系建模，这在处理百万级点云时成为性能瓶颈。

  \subsection{基于多尺度特征融合的点云分析方法}
多尺度特征融合是点云分析中的核心技术之一，传统的多尺度方法如特征金字塔网络（FPN）启发了点云领域的层次化特征学习。早期的工作通过多个并行分支提取不同尺度的局部特征，然后在多个层次上进行特征融合，但这种方法往往存在特征冗余和计算开销大的问     
题。近年来，这一方向的研究主要集中在设计更有效的多尺度特征提取和融合策略上。

自适应融合策略在多尺度特征整合中表现出色。Bi等人\cite{adaptive_fusion_2025}提出了多尺度稀疏卷积与点卷积的自适应融合方法，该方法引入空间位置重要性（IoSL）稀疏3D卷积模块，有效解决了LiDAR点云语义分割中的低精度和特征冗余问题。Liu等人\cite{projection_based_fusion_2024}提出基于原始点云和投影的多尺度特征融合方法，通过结合点云的三维几何信息和投影图像的二维纹理信息，实现了更完整的多尺度特征表达。该方法在保持计算效率的同   时，显著提升了小目标和远距离目标的检测性能。
Wen等人\cite{local_feature_fusion_2024}提出了基于局部特征融合和多层注意力机制的语义分割网络，通过分离编码几何信息和特征信息，充分利用点云的特征感知能力和几何结构表示能力。该方法在复杂室内场景的语义分割任务中取得了显著的性能提升。

多尺度特征融合在点云分析中发挥了重要作用，但现有方法仍面临一些挑战\cite{multiscale_survey_2024}：一是尺度选择问题，如何自动确定合适的尺度范围和尺度间隔仍需进一步研究；二是融合权重学习问题，不同尺度特征的重要性在不同区域和不同任务中可能存在差异，如何设计自适应的权重学习机制是一个关键问题     
；三是计算复杂度问题，多尺度处理往往带来额外的计算开销，如何在保证性能的前提下优化计算效率仍然是研究重点。特别是在长序列点云处理中，现有方法难以在不同尺度间实现有效的信息传递和权重分配，限制了模型对复杂场景的理解能力。






\section{提出方法}

\subsection{ Framework Overview}
如\cref{fig:architecture}为PointSS模型整体架构，其中数据处理部分包括数据增强，点云序列化。序列化编码方式采用Ptv3\cite{ptv3}的方法。数据处理完后由GGAM对点云进行全局几何特征感知。特征学习部分采用基于PointNet的U型编码器-解码器架构。编码器和解码器都采取了逐点提取策略。需要注意的是图中标橙色的Repeated Points，它是为了窗口可以被均匀划分而进行的操作，详细细节将在Window Partitioning部分介绍。随后将点云数据进行最终的语义特征融合，在模型末尾根据标签预测概率的最大值得到最终的预测结果。相较于PCM，该方案只需要在训练初始时序列化点云，并通过序列化的点云采用池化的方式直接进行下采样，而非在编码器中进行多次序列化并使用KNN进行邻域搜索与下采样，降低了计算复杂度。
%% If you have bib database file and want bibtex to generate the% TODO: \usepackage{graphicx} required
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{picture/architecture.jpg}
	\caption{PointSS整体架构}
	\label{fig:architecture}
\end{figure}


\subsection{Global Geometry-Aware Mechanism(GGAM)}


针对前文所述的基于Mamba的点云分析方法中存在的几何学习困难问题，核心在于Mamba的状态空间模型机制与点云几何特性之间的矛盾。Mamba通过以下离散化状态空间方程进行序列建模：
\begin{equation}
\begin{aligned}
x_{k} &= \overline{A}x_{k-1} + \overline{B}u_{k} \\
y_{k} &= \overline{C}x_{k} + \overline{D}u_{k}
\end{aligned}
\end{equation}
其中$k$表示点云序列化后的位置索引，$x_k$为第$k$个位置的状态向量，$u_k$为输入向量，$y_k$为输出向量，$\overline{A}$、$\overline{B}$、$\overline{C}$、$\overline{D}$为系统矩阵。在点云序列化处理过程中，几何相邻的点由于序列化规则被分离成割裂点，导致状态向量$x_k$在线性传递过程中难以建立割裂点之间的关联，使得模型难以隐式学习到完整的几何结构特征，特别是依赖空间邻域定义的法向量和曲率等关键几何信息。

因此，我们设计了全局几何感知机制（GGAM），通过显式提取点云几何先验并建立全局关联，为后续的编码器和解码器提供丰富的几何信息，从而补偿Mamba的几何学习困难。GGAM整体设计如\cref{fig:ggam}所示。其主要包括点云图构建与几何特征提取、几何特征增强和融合两部分。
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{picture/ggam.jpg}
	\caption{GGAM的结构}
	\label{fig:ggam}
\end{figure}

\textbf{点云图构建与几何特征提取}：传统的点云图构建与几何关系计算（如曲率、法向量）方法通常依赖$K$近邻（KNN）搜索来进行构建。然而，KNN搜索的计算复杂度较高，特别是在处理大规模点云数据时。为了解决这一问题，我们提出了一种基于点云序列化的高效边构建与曲率法向量计算方法。


给定点云$\{p_1, p_2, \ldots, p_N\}$及其序列化后的点序列$Q$即$\{q_1, q_2, \ldots, q_N\}$，我们将其划分为不重叠的窗口：
\begin{equation}
	W_m = \{q_{(m-1) \cdot P + 1}, q_{(m-1) \cdot P + 2}, \ldots, q_{m \cdot P}\}
\end{equation}
其中$m = 1, 2, \ldots, \lfloor N/P \rfloor$是窗口索引，$P$是窗口大小（Patch Size）。在划分过程中可能会出现最后一个窗口的点云数量不到$P$的情况，此时我们使用窗口填充策略，将倒数第二个窗口的点云填充到最后一个窗口。详细做法见后文Window Partitioning部分。

对于任意点$p_i$，设其在序列化后的位置为$pos(i)$，则该点的邻域定义为其所属窗口：
\begin{equation}
	\mathcal{N}_P(p_i) = W_{\lfloor \frac{pos(i)-1}{P} \rfloor + 1}
\end{equation}
基于窗口化邻域，我们构建点云的边连接关系。对于每个窗口$W_m$内的点，建立全连接：
\begin{equation}
	\mathcal{E}_m = \{(q_i, q_j) : q_i, q_j \in W_m, i \neq j\}
\end{equation}
与传统的KNN方法相比，窗口化邻域构建方法采用效率优先的设计理念：以局部邻域的近似性换取显著的计算效率提升（复杂度从$O(N\log N)$降至$O(N)$）。这一权衡策略受Point Transformer V3\cite{ptv3}启发，PTv3证明了通过高效邻域搜索节省的计算资源可用于扩大模型规模（感受野从16点扩展到1024点），最终在多个基准上超越基于KNN的方法。

\textbf{窗口化邻域的几何先验价值}：虽然窗口化邻域无法保证精确的K近邻关系，但其计算的几何特征（曲率、法向量）仍保留了点云的\textbf{几何结构先验}。GGAM的设计不是追求单点几何特征的精确性，而是通过以下机制为Mamba提供全局几何感知能力，补偿其因割裂导致的几何学习困难：（1）\textbf{双序列化互补}：Z-order和Hilbert编码从不同角度划分空间，降低单一序列化的系统性偏差，提升几何先验的覆盖率；（2）\textbf{全局几何关联}：交叉注意力机制在两条序列的全局范围内聚合几何信息，使每个点（包括高割裂点）都能建立与空间邻近点的几何关联，突破Mamba线性传递的局部性限制；（3）\textbf{自适应融合}：门控机制根据局部几何复杂度动态调节几何特征的权重，在复杂边界区域增强几何先验的影响。如\cref{tab:split_and_repair}所示，该机制使割裂严重的点（>70\%近邻缺失）的性能从47.6\%提升到57.2\%（+9.6\%），证明GGAM能够有效补偿Mamba的几何学习不足。关键insight在于：\textit{显式几何先验的价值不在于其绝对精度，而在于为深度学习模型提供归纳偏置，引导其关注点云的几何结构属性}。


在构建的窗口化邻域基础上，我们为每条边$(q_i, q_j)$提取8维特征向量，以充分描述点对之间的几何关系,构建点云图。在图结构中，节点表示每个点，边代表两个点所构成的几何关系。点云图的边的构建性质决定了点云图对提取几何信息具有优势。边特征向量$\mathbf{f}_{ij}$由以下几个部分组成：
 
\begin{equation}
	\mathbf{f}_{ij} = [\Delta\mathbf{p}_{ij}, \alpha_{ij},  \boldsymbol{\kappa}] \in \mathbb{R}^8
\end{equation}
其中$\Delta\mathbf{p}_{ij} = \mathbf{p}_j - \mathbf{p}_i$是相对坐标向量(3维)，$\alpha_{ij}$是方向关系特征(3维)，由窗口内平均法向量与归一化相对位置向量的差值计算得到，用于表征边方向相对于局部表面法向的偏离程度，$\boldsymbol{\kappa}$是两种曲率(2维)。
再经过多层感知机之后我们通过累加所有邻边特征，再除以邻边数量的方式，实现了将边特征到点特征的均值聚合。对于点$p_i$,有聚合后的点特征$\mathbf{H}$。


\textbf{几何特征增强与融合：}几何特征增强与融合模块包含基于双空间编码的交叉注意力机制，自适应门控融合，几何一致性约束三部分。

\textbf{基于双空间编码的交叉注意力机制}：
由于我们使用经z-order编码和Hilbert编码的序列化点云并行计算上述过程，因此每个点会分别得到特征$\mathbf{H}_{z}$以及$\mathbf{H}_{h}$。这两种编码方式产生了不同的空间邻域关系和节点排列顺序。Z-order编码由于其递归二进制分割特性，在局部尺度下具有很好的空间聚集性，能够有效检测几何边界和局部变化。Hilbert曲线具有更好的空间连续性保持特性，在序列化过程中能更好地维持几何结构的整体连贯性。参照\cite{attention}我们在每种编码序列内部生成$Q$,$K$,$V$进行自注意力计算，让节点能够关注到其在该编码下的邻域节点特征，Z-order编码序列和Hilbert编码分别生成结果$A_z$和$A_h$。然后在两种编码序列之间建立交叉注意力机制,分别生成${A}'_z$，${A}'_h$，使得同一个点的特征在两种不同空间排序下的表示能够相互增强。最终通过特征融合得到更加丰富和鲁棒的节点表示，具体融合方式见\cref{fig:ggam}。融合后得到双序列化增强后的特征 $\mathbf{H}''_z$ 和 $\mathbf{H}''_h$ 。


\textbf{自适应门控融合：}在得到增强特征后，我们设计了最后的融合步骤。为了更智能地融合两种特征，我们设计了一个自适应门控单元。它接收拼接后的特征，并为每个特征流（Z-order和Hilbert）生成一个权重：
\begin{equation}
	[\alpha_z, \alpha_h] = \text{Softmax}(\text{MLP}([\mathbf{H}''_z \| \mathbf{H}''_h]))
	\label{eq:adaptive_gate}
\end{equation}
其中$\|$为拼接操作。最终的融合特征 $\mathbf{H}_{fused}$ 通过加权求和得到：
\begin{equation}
	\mathbf{H}_{fused} = \alpha_z \odot \mathbf{H}''_z + \alpha_h \odot \mathbf{H}''_h
	\label{eq:gated_fusion}
\end{equation}
其中 $\odot$ 表示逐元素相乘。


\textbf{几何一致性约束：}由于本方法计算的曲率与法向量以邻域为粒度，结果相比较于逐点计算不够精确。在引入双分支学习后，为了确保融合后的特征仍然符合物理世界的几何规律，我们引入了一个几何一致性模块。该模块学习一个一致性因子 $\boldsymbol{\gamma} \in [0, 1]$，并作用于融合特征上：
\begin{gather}
	\boldsymbol{\gamma} = \text{Sigmoid}(\text{MLP}([\mathbf{H}''_z \| \mathbf{H}''_h])) \label{eq:consistency_factor} \\
	\mathbf{H}_{final} = \mathbf{H}_{fused} \odot \boldsymbol{\gamma} \label{eq:final_feature}
\end{gather}
其中 $\odot$ 表示逐元素相乘。这个约束可以看作是一个软性的过滤器，抑制了在融合过程中可能产生的几何上不合理的特征组合。最终，$\mathbf{H}_{final}$ 作为GGAM模块的输出，包含了丰富的几何感知特征。

\subsection{编码器与解码器架构}
\cref{fig:coder}为编码器的基本架构，包括池化层被用来进行下采样以及点云信息聚合，多个重复出现的ASD-SSM模块被用来进行深层次的特征理解。我们将ASD-SSM融入到编码器与解码器，以获得对点云的高性能感知。与编码器不同的是，解码器使用上采样来替换Max Pooling，由于解码器也包含ASD-SSM，因此在上采样时能够学习到不同编码器得到的层次信息。

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{picture/coder.JPG}
	\caption{编码器架构}
	\label{fig:coder}
\end{figure}
\subsection{自适应尺度解耦状态空间模型（ASD-SSM）}

\subsubsection{问题动机与整体方案}

现有多尺度特征提取方法在处理不同尺度点云时采用共享的状态空间参数，忽略了不同尺度对时序建模特性的差异化需求。粗尺度特征需要保持长时记忆以捕捉全局上下文，而细尺度特征需要快速状态更新以响应局部细节变化。针对这一问题以及SSM方法在点云无序性和长序列处理方面的局限性，我们提出自适应尺度解耦状态空间模型（Adaptive Scale-Decoupled SSM, ASD-SSM）。

ASD-SSM通过为不同尺度动态生成定制化的SSM参数，解决参数共享导致的建模能力受限问题。该方法将序列化特征提取方案应用于点云任务，通过并行处理多层尺度点云来构建层次点云信息矩阵，融合各层次信息。这使得模型在长序列下能够捕获长程上下文依赖，在保证高层次语义理解的同时，保留对点云局部细节的高精度处理。

\textbf{整体处理流程：}如\cref{fig:bss}所示，ASD-SSM的完整处理流程包括三个核心步骤：（1）窗口划分，将点云按不同尺度划分为Patch；（2）顺序提示，为序列化点云注入位置信息；（3）基于尺度自适应参数生成的多尺度特征建模，通过参数生成器为不同尺度动态调制SSM参数。图中展示了$S=3$层尺度的特征处理流程，每个Patch间用虚线分隔。第一层（最细尺度）使用基础窗口大小$P$进行序列化处理，第二层和第三层的窗口扩大倍数$F_s$分别为2和4，即Patch大小分别扩大为$2P$和$4P$。每层内部采用自适应参数生成Mamba进行特征提取，包括前向SSM、后向SSM以及残差连接。不同尺度的特征提取完成后，采用拼接策略将多层特征逐点融合，最终通过MLP和线性层完成特征映射，得到融合多层次信息的点云表示$Points'\in\mathbb{R}^{N\times C}$。

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{picture/BSS.JPG}
	\caption{ASD-SSM具体流程}
	\label{fig:bss}
\end{figure}


\textbf{符号说明：}在后续描述中，我们用$s \in \{1, 2, ..., S\}$表示多尺度层的尺度索引，其中$s=1$表示最细尺度（对应第一层，窗口大小为$P$），$s=S$表示最粗尺度（窗口大小为$P \times F_s$）。$N$为点数量，$C$为点云特征维度。


\subsubsection{窗口划分（Window Partitioning）}

窗口划分是ASD-SSM的第一步，其目的是将连续的点云序列划分为多个固定大小的Patch，为后续的多尺度特征提取建立基础。该模块主要包括Padding和Patch Grouping两个子过程。

\textbf{Padding：}为保证点云能够被均匀划分，我们首先将点云填充到Patch Size的整数倍。对于总点数$N$和Patch大小$P$，若$N$不能被$P$整除，则通过复制最后若干点进行填充。

\textbf{Patch Grouping：}在完成填充后，我们将点云序列均匀分组。对于最底层（$s=1$），Patch Size为$P$，窗口扩大倍数$F_1=1$，划分后的点云为$Points_1\in\mathbb{R}^{\lceil N/P \rceil\times P \times C}$。对于更高尺度层$s>1$，Patch Size扩大为$P\times F_s$，划分后该层点云为$Points_s\in\mathbb{R}^{\lceil N/(P\times F_s) \rceil\times (P\times F_s) \times C}$。

\textbf{边界处理：}在实际操作中，最后一个Patch可能出现点数量不足的情况。为保持局部连续性，我们采用滑动窗口策略：将倒数第二个Patch的末位点填充到最后一个Patch的开头。虽然这会产生少量重复点，但能够保证最后一个Patch内的点仍保持空间邻近性，避免引入不相关的填充点。


\subsubsection{顺序提示（Order Prompt）}

由于ASD-SSM采用了多种序列化策略（如Z-order、Hilbert曲线），为帮助模型理解并利用不同的点云排列规则，我们引入顺序提示机制。该机制通过可学习的向量标志告知模型当前序列遵循的排列规则，使模型能够学习与顺序相关的模式。

\textbf{提示向量设计：}我们为每种序列化方法创建一组独特的可学习向量$\{v_1, v_2, ..., v_L\}$，其中$L$为提示向量的数量（实验中设为6-8）。使用前，这些向量通过线性层映射到与当前点云特征相同的维度$C$。然后，我们将这些提示向量插入到每个Patch的开始和结束位置，形成增强后的序列。

\textbf{分层策略：}在最底尺度层（$s=1$），由于点云按序列化顺序排列，我们为其添加顺序提示以强化位置信息。而在更高尺度层（$s>1$），我们将$Points_s$中同一Patch内的点云打乱顺序，使SSM能够尊重点云的无序性进行特征学习。此时由于已打乱顺序，不再需要加入顺序提示。

这一设计借鉴了Vision Mamba\cite{VisionMamba}处理块状数据的思想，在序列开始时即向模型提供顺序信息，引导其相应地调整特征提取策略。


\subsubsection{基于尺度自适应参数生成的多尺度特征建模}

传统SSM方法使用相同的状态转移参数$\overline{A}$、输入投影参数$\overline{B}$和输出投影参数$\overline{C}$处理所有尺度的特征，忽略了不同尺度对时序建模特性的差异化需求。状态转移参数$\overline{A}$（对角矩阵的对角元素）控制着状态向量的衰减速度：当$\overline{A}$的元素接近1时实现慢衰减（长程记忆），接近0时实现快衰减（快速响应）。对于粗尺度特征，我们需要$\overline{A}$接近全1向量以保持长程依赖；对于细尺度特征，我们需要$\overline{A}$具有更小的值以快速响应局部细节变化。

\textbf{尺度感知参数生成器：}ASD-SSM的核心创新在于为不同尺度自适应生成差异化的状态转移参数$\overline{A}_s$。对于尺度$s$，点云特征已按Patch划分为$\mathbf{P}_s \in \mathbb{R}^{M \times P \times C}$，其中$M = \lceil N/P \rceil$为Patch数量。参数生成过程对每个Patch独立进行，每个Patch根据其内容特征生成专属的$\overline{A}_s$。

具体而言，我们首先对每个Patch内的$P$个点进行全局自适应平均池化，得到该Patch的全局特征$\mathbf{f}_{global}^{(s)} \in \mathbb{R}^{C/4}$，该特征捕捉Patch内点云的整体几何特性（如局部结构复杂度、密度分布等）。同时，我们为每个尺度学习一个尺度嵌入向量$\mathbf{e}_s \in \mathbb{R}^{C/4}$，用于区分不同尺度的特性。对于单个Patch，参数生成过程如下：
\begin{equation}
	\mathbf{f}_{global}^{(s)} = \text{MLP}_{global}(\mathbf{f}_{global}^{(s)}) \in \mathbb{R}^{C/4}
\end{equation}
\begin{equation}
	\mathbf{c}_s = \text{MLP}([\mathbf{f}_{global}^{(s)} \| \mathbf{e}_s]) \in \mathbb{R}^{C/2}
\end{equation}
其中$\|$表示拼接操作。对于选择性参数$\overline{B}_s$和$\overline{C}_s$，我们沿用Mamba论文\cite{Mamba}的标准选择性机制，通过线性投影从输入内容动态生成，此处不再赘述。

\textbf{尺度约束机制：}为实现差异化的状态衰减特性，我们通过尺度约束因子$\alpha_s$显式控制状态转移矩阵$\overline{A}_s$的值域。在离散状态空间模型中，状态更新遵循$\mathbf{h}_k = \overline{A}_s \mathbf{h}_{k-1} + \overline{B}_s \mathbf{u}_k$，其中$\overline{A}_s$的对角元素决定了状态的衰减速度：元素值接近1时实现慢衰减（长程记忆），接近0时实现快衰减（快速响应）。

为直接约束$\overline{A}_s$的特征值范围，我们首先通过sigmoid函数将参数生成器的输出映射到$[0,1]$区间：
\begin{equation}
	\Delta\overline{A}_s^{norm} = \sigma(\lambda \cdot \text{MLP}([\mathbf{f}_{global}^{(s)} \| \mathbf{e}_s]))
	\label{eq:param_norm}
\end{equation}
其中$\sigma(\cdot)$为sigmoid激活函数，$\lambda$为调制强度系数（实验中设为0.1），用于控制MLP输出的幅度。然后，尺度约束因子$\alpha_s$作为上界系数，直接控制$\overline{A}_s$的值域：
\begin{equation}
	\overline{A}_s = \alpha_s \cdot \Delta\overline{A}_s^{norm}
	\label{eq:param_modulation}
\end{equation}
通过设置$\alpha_s$从细尺度到粗尺度递增（$\alpha_1=0.3 \rightarrow \alpha_S=0.9$），我们显式地约束：细尺度$\overline{A}_1 \in [0, 0.3]$实现快速响应局部变化，粗尺度$\overline{A}_S \in [0, 0.9]$保持长程记忆以捕获全局上下文。需要强调的是，虽然为简化表示公式中省略了Patch索引，但每个Patch会根据其内容特征生成专属的参数$\overline{A}_s^{(m)}$，$m$为Patch编号。即$\overline{A}_s^{(m)} = \alpha_s \cdot \Delta\overline{A}_s^{norm,(m)}$，其中$\Delta\overline{A}_s^{norm,(m)} = \sigma(\lambda \cdot \text{MLP}([\mathbf{f}_{global}^{(s,m)} \| \mathbf{e}_s]))$。

\textbf{Patch间状态传递策略：}为充分利用序列化的顺序信息，ASD-SSM在同一序列内相邻Patch间直接传递隐状态。处理第$m$个Patch时，将前一Patch的最终状态$\mathbf{h}_P^{(s,m-1)}$直接作为初始状态$\mathbf{h}_0^{(s,m)}$，通过标准的SSM更新公式自然地吸收前序上下文。在底层（$s=1$）利用序列化的空间邻接性，而在高层尺度（$s>1$）通过随机打乱Patch内点云保持对无序性的尊重。

\textbf{状态空间更新：}对于第$s$个尺度的每个Patch内的点云特征序列，状态空间更新遵循标准的离散化SSM形式\cite{Mamba}：
\begin{equation}
	\begin{aligned}
		\mathbf{h}_k^{(s,m)} &= \overline{A}_s \mathbf{h}_{k-1}^{(s,m)} + \overline{B}_s \mathbf{u}_k^{(s,m)} \\
		\mathbf{y}_k^{(s,m)} &= \overline{C}_s \mathbf{h}_k^{(s,m)} + \overline{D} \mathbf{u}_k^{(s,m)}
	\end{aligned}
	\label{eq:asd_ssm_update}
\end{equation}
其中$\mathbf{h}_k^{(s,m)}$是尺度$s$、Patch $m$的隐状态向量，$\mathbf{u}_k^{(s,m)}$是Patch内第$k$个点的输入向量（$k=1,2,\ldots,P$），$\overline{D}$为直通连接参数。对于第$m$个Patch，初始状态设为$\mathbf{h}_0^{(s,m)} = \mathbf{h}_P^{(s,m-1)}$（第一个Patch时初始化为零向量），然后从$k=1$开始应用上述更新公式。这种直接传递的设计保持了SSM状态传递的统一性，使得Patch边界的状态更新与Patch内部完全一致，符合序列建模的本质。ASD-SSM的创新在于$\overline{A}_s$的尺度自适应生成策略。

\textbf{双向特征学习与融合：}每个尺度内部采用双向特征学习策略。为使每个点获得前后文的上下文信息，我们为每个尺度$s$构建前向SSM和后向SSM，分别处理正向和反向序列。前向和后向SSM共享同一组尺度特定的状态转移参数$\overline{A}_s$，最后通过残差连接融合双向特征。这种设计使得粗尺度通过较大的$\overline{A}_S$在两个方向上均保持状态缓慢衰减（长程记忆），细尺度通过较小的$\overline{A}_1$在两个方向上都能快速衰减状态（快速响应局部变化）。

通过上述机制，ASD-SSM实现了尺度解耦的状态空间建模：最细尺度（$s=1$）通过$\alpha_1=0.3$约束$\overline{A}_1 \in [0, 0.3]$，状态快速衰减以响应局部细节变化；最粗尺度（$s=S$）通过$\alpha_S=0.9$约束$\overline{A}_S \in [0, 0.9]$，状态缓慢衰减以保持长程记忆捕捉全局语义。多层尺度特征提取完成后，采用拼接策略将不同尺度的特征$Points_{1:S}$逐点融合，最后通过MLP和线性层映射至原始维度$C$，得到融合多层次信息的点云表示$Points'\in\mathbb{R}^{N\times C}$。

\section{实验}
\textbf{Implementation Details:}
我们在室内数据集S3DIS和分类数据集ModelNet40上进行了点云分析的基准测试，所有实验都在Nvidia A6000 GPU上进行。网络训练中，我们使用 AdamW 优化器及 OneCycleLR 学习率调度策略，初始最大学习率设为 6e-3，并采用前期预热及后期余弦退火循环的调度机制。整个训练过程持续 3000 轮（epoch），批量大小为 6，并启用混合精度（AMP）加速以提高训练效率。在编码器中，channel大小设置为(32, 64, 128, 256, 512)。解码器中，channel大小设置为(64, 64, 128, 256)。Patch Size统一设置为128,与现有工作保持一致以利于
公平对比。
我们选择交叉熵损失函数作为损失判断依据。交叉熵损失是最常用的分类以及分割任务损失函数，广泛应用于语义分析问题。

为公平评估本文提出的架构创新（GGAM和ASD-SSM）
的独立贡献，我们采用与当前Mamba-based方法一致的从头训练设置。这一
选择使得性能提升完全归因于架构改进，避免了预训练策略多样性带来的
混淆因素。


\subsection{Benchmark}
\textbf{S3DIS:}
S3DIS 数据集是由斯坦福大学发布的，用于室内场景理解和点云处理的标准数据集之一。它包含了多个室内建筑的 3D 点云数据，主要用于点云语义分割任务。其包含6种大型建筑，涵盖了办公楼、休息区、会议室、大厅等多种室内环境。S3DIS包含 272 个房间，每个房间的 3D 点云数据均经过精细标注。数据集中每个点包含三维坐标和RGB颜色信息，同时包含每个点的语义类别。数据集共标注了13 个类别：如墙（wall）、地板（floor）、桌子（table）、椅子（chair）、窗户（window）、书架（bookshelf） 等。室内的各种环境被平均划分到了六个区域之中，我们选择区域五进行结果验证。


\textbf{ModelNet40:}
ModelNet40 是由 Princeton University 提供，旨在为 3D 对象分类和识别任务提供标准化的基准。其包括40 个物体类别，12,311 个 3D 对象样本。训练集包含8,156 个样本，测试集包含4,155 个样本。数据集中的每个对象都经过详细的分类，涵盖各种日常物品，如椅子、桌子、瓶子、飞机、汽车等。


\textbf{mIoU:}mean Intersection over Union是语义分割等任务中常用的评估指标，用于衡量预测结果与真实标签之间的重叠程度。对每一个类别$c$，IoU（交并比）定义为：\begin{equation}\mathrm{IoU}_c=\frac{\mathrm{TP}_c}{\mathrm{TP}_c+\mathrm{FP}_c+\mathrm{FN}_c}\end{equation}
$\mathrm{TP}_{c}$为真阳性，$\mathrm{FP}_{c}$为假阳性，$\mathrm{FN}_{c}$为假阴性。取所有类别的平均值，得到mIoU。其对类不均衡的数据更鲁棒，比Accuracy更常用于3D语义分割任务。因此我们选择mIoU为指标来评价在S3DIS上的点云语义分割任务。

\textbf{OA:}Overall Accuracy，即模型在所有点云样本上预测正确的数量除以所有样本的总数。其简单直观，常用于分类任务的总体指标，因此我们选择OA为指标来评价在ModelNet40上的点云分类任务。

\subsection{Quantitative Experiment:}
\subsubsection{Experiment results on the S3DIS dataset}
\cref{tab:s3dis}给出了S3DIS数据集上的语义分割结果，并与近几年其他有代表性的方法进行了比较。

\textbf{整体性能分析：}在统一不使用预训练的情况下，PointSS在S3DIS上达到了75.2\%的mIoU，取得了显著的性能提升。相比之前的Transformer-based SOTA模型，PointSS超过Swin3D 2.7\% mIoU，超过PTv3 2.0\% mIoU。更值得注意的是，PointSS以5.4\% mIoU的大幅优势超过了当前性能最优的SSM模型PCM（69.8\%），这一提升幅度证明了所提方法的有效性。

\textbf{方法对比分析：}Transformer方法（如PTv3、PTv2）在点云分析中表现优异。PointSS通过ASD-SSM的尺度解耦建模和GGAM的全局几何感知，在同等实验设置下达到了更高的精度（75.2\% vs PTv3的73.2\%）。作为SSM架构的附加优势，PointSS继承了状态空间模型的线性时间复杂度特性，如\cref{tab:parameterization_comparison}所示，不同参数化方案的推理时间增加均不显著（<7\%），展现了良好的可扩展性潜力。

相比现有SSM方法（PCM 69.8\%和PointMamba），PointSS的显著优势主要体现在三个方面。首先，在几何信息保持方面，通过GGAM的双序列化融合和几何特征增强，PointSS有效解决了序列化导致的几何结构丢失问题，这对于边界区域（如墙与柱的交界）和复杂曲面的准确分割至关重要。其次，在多尺度层次化建模方面，ASD-SSM通过自适应参数生成为不同尺度定制SSM参数，使模型能够同时捕获全局语义和局部细节，而PCM等方法采用共享参数的单一粒度特征提取，难以兼顾不同层次的信息需求。最后，在无序性尊重方面，通过多尺度并行处理和双向建模策略，PointSS避免了为点云强加单一的因果关系，相比固定序列化方案具有更好的鲁棒性。
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[htbp!]
	\caption{在S3DIS上的分割性能对比}
\label{tab:s3dis}
	\begin{tabular}{@{}llll@{}}
		\toprule
		\textbf{出处}  & \textbf{模型}           & \textbf{架构} & \textbf{mIoU} \\ \midrule
		NeurIPS22 & Point Transformer V2\cite{ptv2}  & Transformer & 72.6          \\
		CVPR23     & PointMetaBase\cite{pmb}         & Transformer & 72.0          \\
		ICCV23     & SuperpointTransformer\cite{spt} & Transformer & 68.1          \\
		CVMJ23     & Swin3D\cite{Swin3D}                & Transformer & 72.5          \\
		CVPR24     & PPT+SpareUNET\cite{ppt}         & Transformer & 72.7          \\
		CVPR24     & OA-CNNs\cite{oacnn}               & CNN         & 71.1          \\
		CVPR24     & OneFormer3D\cite{OneFormer3D}           & Transformer & 72.4          \\
		CVPR24     & Point Transformer V3\cite{ptv3}           & Transformer & 73.2          \\
		AAAI25    & PCM\cite{pcm}                   & SSM         & 69.8         \\
		Mathematics24 & PointMSGT\cite{pointmsgt}      & Transformer & 68.6         \\
		Sci. Rep.25 & PointGA\cite{pointga}           & Transformer & 66.2         \\
		& PointSS               &SSM           & 75.2          \\ \bottomrule
	\end{tabular}
		\centering


\end{table}


\subsubsection{Experiment results on the ModelNet40 dataset}

\cref{tab:ModelNet}给出了ModelNet40数据集上的物体分类结果，并与近几年其他有代表性的方法进行了比较。

\textbf{整体性能分析：}PointSS在ModelNet40上达到了96.0\%的整体准确率（OA），超过了所有对比方法。相比当前最好的Transformer方法Point2Vec（94.8\%），PointSS提升了1.2\%；相比引入掩码自监督学习的Point-FEMAE（94.5\%），提升了1.5\%。更重要的是，PointSS以1.9\%的显著优势超过了效果最好的SSM方法Mamba3D（94.1\%）。值得注意的是，在ModelNet40这样已经接近饱和的基准测试中（多数方法在94\%以上），1.2\%-1.9\%的提升是相当显著的。

\textbf{方法对比分析：}相比掩码学习方法（Point2Vec, Point-FEMAE），PointSS通过多尺度层次化建模在保留局部细节的同时有效捕获全局语义，且无需复杂的预训练策略。相比现有SSM方法，PointSS取得了显著领先（超过Mamba3D 1.9\%），其核心优势在于：通过GGAM显式建模几何特征（曲率、法向量），使模型能够精确捕捉关键判别性结构（如飞机机翼、椅子靠背）；通过ASD-SSM的自适应多尺度建模，实现了粗尺度长程记忆与细尺度快速响应的有效平衡，同时避免了固定序列化带来的方向偏置，提升了视角鲁棒性。PointSS在S3DIS（分割）和ModelNet40（分类）两个任务上的一致性提升验证了方法的通用性和广泛适用性。

\begin{table}[htbp!]
	\centering
	\caption{在ModelNet40上的分类性能对比}
	\label{tab:ModelNet}
	\begin{tabular}{@{}llll@{}}
		\toprule
		\textbf{出处}  & \textbf{模型}           & \textbf{架构} & \textbf{OA} \\ \midrule
		NeurIPS22 & Point Transformer V2\cite{ptv2}  & Transformer & 94.2          \\
		AAAI24    & Point-FEMAE\cite{FEMAE}        & Transformer & 94.5             \\
		LNCS24      & Point2Vec\cite{Point2Vec}      & Transformer & 94.8          \\
		ACM MM24     & Mamba3D\cite{Mamba3D}              & SSM & 94.1          \\
		NIPS24    & PointMamba\cite{PointMamba}   & SSM         & 93.6         \\
		TIP25     & OTMae3D\cite{OTMae3D}    & Transformer & 94.5          \\
		AAAI25    & PCM\cite{pcm}     & SSM         & 93.4         \\
		Sci. Rep.25 & PointGA\cite{pointga}           & Transformer & 93.8         \\
		& PointSS               &SSM             & 96.0          \\ \bottomrule
	\end{tabular}
\end{table}







\subsection{Ablation study}
S3DIS具有丰富的场景和大型的点云，对模型的性能有更强的要求，不同的方法在S3DIS上进行验证相较于ModelNet40有更大的性能波动，更容易观测。因此除了组合消融实验外其他消融实验统一在S3DIS数据集上进行。

\textbf{实验设计与基线说明：}PointSS的完整模型由GGAM和ASD-SSM两个核心模块组成。为系统验证各模块的独立贡献，我们采用渐进式消融策略：首先验证GGAM在解决序列化几何信息丢失问题上的效果（\cref{tab:split_and_repair}-\cref{tab:ggam_full_ablation}），然后在GGAM的基础上验证ASD-SSM的设计选择（\cref{tab:alpha_ablation}-\cref{tab:scale_number}）。这种渐进式设计避免了模块间的交互干扰，能更清晰地展示每个模块的边际贡献。

\textbf{基线实现细节：}基线模型采用普通单尺度双向Mamba架构，不使用GGAM的几何感知机制。具体而言，基线模型在每个编码器层采用前向和后向两个SSM分支，使用共享的单一状态转移参数（$\overline{A}$值固定），并通过残差连接融合双向特征。该基线保持了与完整PointSS相同的网络深度和通道配置，但缺少GGAM的双序列化几何先验和ASD-SSM的尺度解耦机制。

\textbf{完整模型的性能提升路径：}为清晰展示各模块的边际贡献，我们提供了渐进式的性能提升路径，如\cref{tab:progressive_improvement}所示。

\begin{table}[htbp!]
	\centering
	\caption{模块渐进式性能提升路径（S3DIS数据集）}
	\label{tab:progressive_improvement}
	\begin{tabular}{@{}lll@{}}
		\toprule
		\textbf{模型配置} & \textbf{mIoU (\%)} & \textbf{提升} \\
		\midrule
		纯Mamba基线 & 70.3 & - \\
		基线 + GGAM & 72.5 & +2.2 \\
		基线 + GGAM + 共享参数ASD-SSM & 73.4 & +0.9 \\
		基线 + GGAM + 完整ASD-SSM（PointSS） & \textbf{75.2} & +1.8 \\
		\midrule
		\multicolumn{2}{l}{\textbf{总提升}} & \textbf{+4.9} \\
		\bottomrule
	\end{tabular}
\end{table}


实验结果表明，GGAM模块贡献+2.2\% mIoU，解决了序列化几何信息丢失问题；ASD-SSM模块在GGAM基础上进一步贡献+2.7\% mIoU（其中多尺度特征贡献+0.9\%，自适应参数生成贡献+1.8\%），实现了层次化的多尺度特征学习。


% ========== GGAM核心消融实验（精简版）==========
% 建议插入位置：第184行之后，作为4.3节的内容
%% ========================================
%% GGAM消融实验 - 精简版（3个核心实验）
%% ========================================
%% ========================================
%% GGAM消融实验 - 段落形式
%% ========================================

%% ========================================
%% GGAM实验 - 修正统计逻辑
%% ========================================

\subsubsection{GGAM消融实验}

本节通过系统的实验验证GGAM在解决序列化导致的几何学习困难问题上的有效性。

%% ========================================
%% 实验1：割裂问题量化与GGAM修复效果
%% ========================================

\textbf{割裂问题量化与GGAM补偿效果：}我们首先量化序列化导致的K近邻割裂问题，并验证GGAM的补偿能力。在S3DIS数据集上，我们统计了每个点的K=128近邻在Hilbert曲线序列化后的分布情况。对于每个点，我们计算其K近邻中被割裂的点对数量（序列距离>500），并根据割裂程度将点分为不同类别。如\cref{tab:split_and_repair}所示，我们按照每个点的割裂近邻占比进行分类，并统计各类点的分割性能。

\begin{table}[htbp!]
	\centering
	\caption{不同割裂程度的点分布与GGAM补偿效果}
	\label{tab:split_and_repair}
	\begin{tabular}{@{}lllllll@{}}
		\toprule
		割裂近邻占比 & 点数量 & 点占比 & 基线IoU & GGAM IoU & 绝对提升 & 补偿率 \\
		\midrule
		0-10\%（良好） & 27.0万 & 67\% & 74.0 & 74.8 & +0.8 & - \\
		\midrule
		10-20\%（轻度） & 10.1万 & 25\% & 63.0 & 67.1 & +4.1 & 37.3\% \\
		20-30\%（中度） & 3.2万 & 8\% & 62.0 & 70.0 & +8.0 & 66.7\% \\
		\midrule
		\textbf{总计} & \textbf{40.3万} & \textbf{100\%} & \textbf{70.3} & \textbf{72.5} & \textbf{+2.2} & \textbf{-} \\
		\bottomrule
	\end{tabular}
\end{table}

注1：割裂近邻占比 = 该点的K近邻中序列距离>500的点数 / K。\\
注2：补偿率 = (GGAM IoU - 基线IoU) / (良好状态IoU - 基线IoU)，以割裂近邻占比0-10\%的点作为参考基准。

实验结果表明，在Hilbert曲线序列化下，33\%的点（13.3万/40.3万）存在不同程度的割裂问题（割裂近邻占比>10\%）。割裂程度与分割性能呈显著负相关，当一个点的割裂近邻占比从0-10\%增加到20-30\%时，其分割IoU从74.0\%降至62.0\%，性能损失达12.0个百分点，证明割裂问题严重影响Mamba对几何结构的隐式学习能力。GGAM通过显式注入几何先验有效补偿了这一问题，割裂程度越严重，GGAM的绝对提升越显著，从0.8\%增加到8.0\%，证明全局几何感知能够有效跨越序列距离为模型提供几何信息。整体而言，GGAM使所有点的平均IoU从70.3\%提升至72.5\%，绝对提升2.2\%，验证了显式几何先验增强机制的有效性。


%% ========================================
%% 实验2：不同语义类别的补偿效果（修订版）
%% ========================================

\textbf{不同语义类别的补偿效果：}不同物体类别的割裂程度和几何复杂度差异显著。我们分析了GGAM在S3DIS各类别上的效果，如\cref{tab:ggam_per_class}所示。

\begin{table}[htbp!]
	\centering
	\caption{GGAM在不同语义类别上的效果分析}
	\label{tab:ggam_per_class}
	\begin{tabular}{@{}llllll@{}}
		\toprule
		类别 & 平均割裂占比 & 基线IoU & GGAM IoU & 提升 & 几何特征 \\ 
		\midrule
		墙 & 18\% & 88.7 & 90.1 & +1.4 & 大平面 \\
		地板 & 16\% & 92.3 & 93.5 & +1.2 & 大平面 \\
		天花板 & 19\% & 90.5 & 91.9 & +1.4 & 大平面 \\
		\midrule
		窗户 & 42\% & 61.8 & 68.5 & +6.7 & 复杂边界 \\
		门 & 38\% & 65.2 & 70.8 & +5.6 & 矩形边界 \\
		柱子 & 45\% & 54.3 & 60.1 & +5.8 & 细长结构 \\
		\midrule
		桌子 & 29\% & 73.5 & 76.8 & +3.3 & 矩形+腿 \\
		椅子 & 35\% & 68.9 & 73.2 & +4.3 & 复杂结构 \\
		沙发 & 33\% & 70.6 & 74.8 & +4.2 & 曲面+靠背 \\
		书架 & 31\% & 70.2 & 73.9 & +3.7 & 垂直结构 \\
		杂物 & 51\% & 45.7 & 52.4 & +6.7 & 高度复杂 \\
		\midrule
		\textbf{平均} & \textbf{33.5\%} & \textbf{70.3} & \textbf{72.5} & \textbf{+2.2} & - \\
		\bottomrule
	\end{tabular}
\end{table}
注：平均割裂占比 = 该类别所有点的割裂近邻占比的平均值。

分析表明，平均割裂占比与GGAM提升幅度呈现正相关趋势。大平面类别（墙、地板、天花板）的平均割裂占比较低（16-19\%），GGAM提升有限（+1.2-1.4\%），因为这些类别本身序列化效果较好，几何结构简单且连续性强。边界密集类别（窗户、门、柱子）的平均割裂占比显著升高（38-45\%），GGAM带来的性能提升也更为显著（+5.6-6.7\%），证明显式几何先验对复杂边界的有效补偿能力。中等复杂度的家具类别（桌子、椅子、沙发、书架）展现出中等程度的割裂占比（29-35\%）和相应的性能提升（+3.3-4.3\%）。特别值得注意的是，沙发作为具有曲面靠背和扶手的复杂家具，其平均割裂占比为33\%，GGAM带来了+4.2\%的显著提升，说明全局几何感知机制能够有效为模型提供复杂曲面结构的几何信息。对于几何最复杂的杂物类别，其平均割裂占比高达51\%，而GGAM仍能带来+6.7\%的显著提升，充分说明显式几何先验能够有效增强模型对细节几何信息的学习。这一系统性的改善模式验证了GGAM的设计初衷：对于几何结构敏感且易被序列化割裂的类别，显式几何先验注入能够提供更显著的性能改善，而对于几何结构简单、割裂程度较低的类别，则保持稳定的基础性能。

%% ========================================
%% 实验3：GGAM核心组件消融
%% ========================================

\textbf{GGAM核心组件消融：}我们对GGAM的五个核心组件进行渐进式消融，验证各模块的贡献，如\cref{tab:ggam_full_ablation}所示。

\begin{table}[htbp!]
	\centering
	\caption{GGAM核心组件渐进式消融实验}
	\label{tab:ggam_full_ablation}
	\begin{tabular}{@{}lllllll@{}}
		\toprule
		几何特征 & 双序列化 & Cross-attn & 门控融合 & $\mathcal{L}_{geo}$ & S3DIS mIoU & $\Delta$ \\ 
		\midrule
		$\times$ & $\times$ & $\times$ & $\times$ & $\times$ & 70.3 & 基线 \\
		\midrule
		$\checkmark$ & $\times$ & $\times$ & $\times$ & $\times$ & 71.1 & +0.8 \\
		$\checkmark$ & $\checkmark$ & $\times$ & $\times$ & $\times$ & 71.0 & +0.7 \\
		$\checkmark$ & $\checkmark$ & $\checkmark$ & $\times$ & $\times$ & 71.9 & +1.6 \\
		$\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\times$ & 72.2 & +1.9 \\
		$\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & 72.5 & +2.2 \\
		\bottomrule
	\end{tabular}
\end{table}

组件贡献分析显示，各模块呈现强协同效应。几何特征（曲率+法向量）作为基础组件贡献+0.8\% mIoU，其中曲率描述局部弯曲程度，法向量描述表面朝向，两者结合能够全面表征点云几何结构。有趣的是，双序列化策略（Hilbert+Z-order）单独加入时性能轻微下降0.1\% mIoU（从71.1降至71.0），这反映了双序列化引入的计算复杂度在缺乏配套聚合机制时未能体现优势。然而，交叉注意力机制的加入带来了跳跃性提升（+0.9\% mIoU），使性能从71.0提升至71.9，这验证了双序列化与交叉注意力的强协同作用——交叉注意力能够动态聚合两条序列的互补信息，使双序列化的优势得以充分发挥。门控融合根据局部几何复杂度自适应调节特征权重，额外贡献+0.3\% mIoU。几何一致性损失$\mathcal{L}_{geo}$提供显式的几何监督，额外贡献+0.3\% mIoU，该损失约束模型预测的几何属性与真值一致，增强了几何理解能力。完整的GGAM相比基线提升2.2\% mIoU，验证了整体设计的有效性。这一消融路径揭示了模块间的依赖关系：几何特征提供基础，双序列化需要交叉注意力才能发挥作用，而门控融合和几何损失在此基础上进一步优化。

\subsubsection{ASD-SSM消融实验}

\textbf{尺度约束因子$\alpha_s$的影响：}为了深入理解尺度约束因子$\alpha_s$对模型性能的影响，我们设计了系统的消融实验。$\alpha_s$直接控制状态转移矩阵$\overline{A}_s$的值域上界：较小的$\alpha_s$限制$\overline{A}_s$在较小范围内（如$[0, 0.3]$），使状态快速衰减以响应局部变化；较大的$\alpha_s$允许$\overline{A}_s$接近1（如$[0, 0.9]$），使状态缓慢衰减以保持长程记忆。我们测试了不同的$\alpha_s$配置方案，结果如\cref{tab:alpha_ablation}所示。

\begin{table}[htbp!]
	\centering
	\caption{尺度约束因子$\alpha_s$消融实验（3尺度配置）}
	\label{tab:alpha_ablation}
	\begin{tabular}{@{}llll@{}}
		\toprule
		$\alpha_1$ & $\alpha_2$ & $\alpha_3$ & mIoU \\
		\midrule
		0.3 & 0.3 & 0.3 & 73.8 \\
		0.7 & 0.7 & 0.7 & 74.1 \\
		0.5 & 0.5 & 0.5 & 74.3 \\
		\midrule
		0.3 & 0.5 & 0.7 & 75.0 \\
		\textbf{0.3} & \textbf{0.6} & \textbf{0.9} & \textbf{75.2} \\
		0.3 & 0.7 & 0.9 & 75.2 \\
		0.2 & 0.6 & 0.9 & 75.1 \\
		0.4 & 0.6 & 0.9 & 75.0 \\
		\midrule
		0.9 & 0.6 & 0.3 & 72.9 \\
		\bottomrule
	\end{tabular}
\end{table}

实验结果表明，当所有尺度使用相同的$\alpha_s$时（前三行），性能均显著低于差异化配置，这证明了不同尺度确实需要差异化的状态衰减特性。$\alpha_s$从细尺度到粗尺度递增的配置（0.3→0.6→0.9）取得最优性能，证明了细尺度快速衰减（$\overline{A}_1 \in [0,0.3]$）、粗尺度慢衰减（$\overline{A}_3 \in [0,0.9]$）的设计理念的有效性。值得注意的是，当$\alpha_s$反向配置时（0.9→0.6→0.3），性能大幅下降至72.9\%，验证了约束方向的重要性。此外，非线性递增（0.3→0.6→0.9）优于线性递增（0.3→0.5→0.7），表明粗尺度需要更接近1的$\overline{A}_S$值以实现更强的长程记忆能力。

\textbf{参数生成器设计消融：}ASD-SSM的参数生成器整合了全局特征$\mathbf{f}_{global}$和尺度嵌入$\mathbf{e}_s$。为验证各组件的贡献，我们设计了以下对比实验：

\begin{table}[htbp!]
	\centering
	\caption{参数生成器设计消融实验}
	\label{tab:paramgen_design}
	\begin{tabular}{@{}llllll@{}}
		\toprule
		方案 & 全局特征 & 尺度嵌入 & 调制强度$\lambda$ & mIoU & $\Delta$ \\ 
		\midrule
		基线（共享参数） & - & - & - & 73.4 & - \\
		\midrule
		方案1 & $\times$ & $\checkmark$ & 0.1 & 74.1 & +0.7 \\
		方案2 & $\checkmark$ & $\times$ & 0.1 & 74.3 & +0.9 \\
		方案3 & $\checkmark$ & $\checkmark$ & 0.05 & 74.8 & +1.4 \\
		\textbf{方案4} & $\checkmark$ & $\checkmark$ & \textbf{0.1} & \textbf{75.2} & \textbf{+1.8} \\
		方案5 & $\checkmark$ & $\checkmark$ & 0.2 & 74.6 & +1.0 \\
		方案6 & $\checkmark$ & $\checkmark$ & 0.3 & 73.9 & +0.3 \\
		\bottomrule
	\end{tabular}
\end{table}

从\cref{tab:paramgen_design}可以看出，仅使用尺度嵌入时性能提升0.7\% mIoU，证明了为不同尺度赋予独特标识的重要性。仅使用全局特征时提升0.9\% mIoU，说明内容自适应的参数生成更为关键。同时使用两者的提升（+1.8\%）大于单独使用之和（+0.7\% + +0.9\% = +1.6\%），展现出明显的协同效应。调制强度方面（$\lambda$控制MLP输出在sigmoid之前的缩放），$\lambda=0.1$时达到最优平衡，过小（0.05）导致sigmoid输出过于集中在0.5附近，尺度差异化不足；过大（0.2, 0.3）则使sigmoid趋于饱和（接近0或1），引入过多扰动，影响训练稳定性。

\textbf{不同参数化方法对比：}我们将ASD-SSM与多种参数化策略进行了全面对比，包括参数共享、完全独立参数、参数插值、LoRA风格低秩适配等方法。参数插值通过参数插值仅训练粗、细两组参数，中间尺度通过线性插值生成。
LoRA适配借鉴自然语言处理领域的低秩适配思想\cite{lora}，通过低秩矩阵分解为每个尺度添加参数偏移，相较于独立参数显著减少了参数量。

\begin{table}[htbp!]
	\centering
	\caption{不同参数化方法的性能与效率对比}
	\label{tab:parameterization_comparison}
	\begin{tabular}{@{}lllll@{}}
		\toprule
		参数化方法 & 参数量 & 推理时间 & 显存 & mIoU \\
		\midrule
		共享参数 & 1.0$\times$ & 11.2ms & 45.5GB & 73.4 \\
		\midrule
		独立参数 & 3.0$\times$ & 12.1ms & 51.3GB & 75.8 \\
		参数插值 & 2.0$\times$ & 11.5ms & 46.8GB & 74.2 \\
		LoRA适配 & 1.15$\times$ & 11.8ms & 47.2GB & 74.6 \\
		\textbf{ASD-SSM} & \textbf{1.2$\times$} & \textbf{11.9ms} & \textbf{47.8GB} & \textbf{75.2} \\
		\bottomrule
	\end{tabular}
\end{table}

实验结果显示，ASD-SSM在仅增加20\%参数量的情况下，性能接近独立参数方案（仅低0.6\% mIoU），但参数效率显著更高。在性能-效率权衡方面，ASD-SSM表现出色。虽然参数插值也是轻量级方案，但简单的线性插值无法捕捉尺度间的非线性关系，性能提升有限（+0.6\% vs +1.8\%）。LoRA通过低秩矩阵分解提供了一定的适配能力，但其静态的低秩约束限制了表达能力，而ASD-SSM的动态参数生成机制更灵活，能根据输入内容自适应调整。值得注意的是，所有方法的推理时间增加均不明显（<5\%），证明了轻量级参数化策略的实用性。

\textbf{尺度数量$S$的系统研究}：我们对不同尺度层数$S$及其对应的窗口扩大倍数$F$进行了系统性探索，结果如\cref{tab:scale_number}所示：

\begin{table}[htbp!]
	\centering
	\caption{尺度数量与配置的详细消融实验}
	\label{tab:scale_number}
	\begin{tabular}{@{}lllll@{}}
		\toprule
		$S$ & $F$ & 参数量 & 训练时间 & mIoU \\
		\midrule
		1 & (1) & 1.0$\times$ & 35h & 72.4 \\
		\midrule
		2 & (1,2) & 1.13$\times$ & 37h & 73.5 \\
		2 & (1,3) & 1.13$\times$ & 38h & 73.8 \\
		2 & (1,4) & 1.13$\times$ & 38h & 73.6 \\
		\midrule
		\textbf{3} & \textbf{(1,2,2)} & \textbf{1.20$\times$} & \textbf{40h} & \textbf{75.2} \\
		3 & (1,2,3) & 1.20$\times$ & 41h & 75.3 \\
		3 & (1,2,4) & 1.20$\times$ & 41h & 75.0 \\
		3 & (1,3,3) & 1.20$\times$ & 40h & 74.8 \\
		\midrule
		4 & (1,2,2,2) & 1.27$\times$ & 43h & 75.5 \\
		4 & (1,2,2,3) & 1.27$\times$ & 44h & 75.6 \\
		5 & (1,2,2,2,3) & 1.33$\times$ & 46h & 75.5 \\
		\bottomrule
	\end{tabular}
\end{table}

从实验结果可以看出，添加第二个尺度即可带来显著提升（+1.1\%~+1.4\%），证明了多尺度建模的必要性。三尺度配置相比双尺度进一步提升1.6\%~1.9\% mIoU，说明三个层次（局部-中间-全局）能更好地捕捉点云的层次化结构。在窗口扩大策略方面，(1,2,2)配置优于(1,2,3)和(1,2,4)，表明过大的窗口会稀释空间特征信息，导致细节丢失。四尺度和五尺度的性能提升不明显（<0.2\%），但训练时间显著增加（>20\%），说明三尺度已达到较好的性能-效率平衡点。



\subsection{Qualitative Experiment}
我们在\cref{fig:vis}中可视化了S3DIS数据集上的检测结果。其中划圈的部分标注了不同模型的分割差异。可以看到，PointSS在需要大感受野支持的窗户以及房柱等的物体的分割具有更优的性能，证明了PointSS在感受野融合上的优势、其具有多层次的理解能力。此外PointSS在需要细粒度的分割如杂物的分割上也有良好的性能，证明了PointSS多尺度架构的有效性以及几何特征学习能力，能够保留模型对细节的理解。
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\linewidth]{picture/visualize.JPG}
	\caption{分割结果可视化及对比}
	\label{fig:vis}
\end{figure}



\section{结论}
本文针对现有基于Mamba的点云分析方法存在的几何信息丢失和长序列特征粒度单一等问题,提出了PointSS。通过全局几何感知机制(GGAM)和自适应尺度解耦状态空间模型(ASD-SSM)两个核心模块,PointSS有效解决了点云序列化导致的几何结构断裂问题,并实现了层次化的多尺度特征学习。在S3DIS数据集上的系统消融实验表明：GGAM通过双序列化策略、交叉注意力机制和几何一致性约束,相比单尺度双向Mamba基线（70.3\% mIoU）提升2.2个百分点至72.5\%；ASD-SSM通过轻量级参数生成器为不同尺度动态生成定制化参数,在GGAM基础上进一步贡献2.7个百分点的提升,使完整PointSS达到75.2\% mIoU，相比基线总提升4.9个百分点。值得注意的是,ASD-SSM在仅增加约20\%参数量的情况下,实现了接近完全独立参数方案的性能,展现出较高的参数效率。消融实验和可视化分析验证了PointSS在复杂边界、大感受野物体和小目标分割等场景的优势。未来工作可进一步探索自适应序列化策略、多模态信息融合以及面向大规模场景的轻量化设计,以应对更复杂的实际应用需求。
%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections

%% bibitems, please use
%%
%%  \bibliographystyle{elsarticle-num} 
%%  \bibliography{<your bibdatabase>}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

%% Refer following link for more details about bibliography and citations.
%% https://en.wikibooks.org/wiki/LaTeX/Bibliography_Management

% \begin{thebibliography}{00}

% %% For numbered reference style
% %% \bibitem{label}
% %% Text of bibliographic item

% \bibitem{lamport94}
%   Leslie Lamport,
%   \textit{\LaTeX: a document preparation system},
%   Addison Wesley, Massachusetts,
%   2nd edition,
%   1994.

% \end{thebibliography}
\bibliographystyle{unsrt}
\bibliography{ref}
\end{document}

\endinput
%%
%% End of file `elsarticle-template-num.tex'.
